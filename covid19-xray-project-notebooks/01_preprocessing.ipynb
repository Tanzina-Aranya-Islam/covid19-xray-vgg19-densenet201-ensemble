{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qk0tGupOUjnOUTjqtUpY3dOzp8IMkah4","authorship_tag":"ABX9TyO9hYsx5j/O4RdBQHgalFRg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T0tqxwNuT3TO","executionInfo":{"status":"ok","timestamp":1763022820854,"user_tz":-360,"elapsed":60825,"user":{"displayName":"Tanzina Aranya Islam","userId":"18148284528936325680"}},"outputId":"80c29300-cd50-4176-88b0-ef6745c864c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["COVID: 3616 images\n","Lung_Opacity: 6012 images\n","Normal: 10192 images\n","Viral Pneumonia: 1345 images\n"]}],"source":["import os\n","\n","dataset_path = \"/content/drive/MyDrive/Dataset Covid19/Covid-19\"\n","\n","categories = [\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\n","\n","for category in categories:\n","    folder_path = os.path.join(dataset_path, category, \"images\")\n","\n","    if os.path.exists(folder_path):\n","        num_images = len([\n","            file for file in os.listdir(folder_path)\n","            if file.lower().endswith(('.png', '.jpg', '.jpeg'))\n","        ])\n","        print(f\"{category}: {num_images} images\")\n","    else:\n","        print(f\"Folder not found: {folder_path}\")\n"]},{"cell_type":"code","source":["import os\n","import cv2\n","import shutil\n","import random\n","from tqdm import tqdm\n","\n","dataset_dir = \"/content/drive/MyDrive/Dataset Covid19/Covid-19\"\n","output_dir = \"/content/drive/MyDrive/Dataset Covid19/Covid-19_processed\"\n","\n","splits = ['train', 'val', 'test']\n","categories = [\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\n","\n","# Create output directories\n","for split in splits:\n","    for category in categories:\n","        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n","\n","\n","def preprocess_image(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img\n","\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","    enhanced = clahe.apply(gray)\n","\n","    # Denoising (Bilateral Filter)\n","    denoised = cv2.bilateralFilter(enhanced, d=9, sigmaColor=75, sigmaSpace=75)\n","\n","    return denoised\n","\n","\n","def split_dataset():\n","    for category in categories:\n","        img_folder = os.path.join(dataset_dir, category, \"images\")\n","        images = [f for f in os.listdir(img_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","        random.shuffle(images)\n","\n","        total = len(images)\n","        train_split = int(total * 0.8)\n","        val_split = int(total * 0.1)\n","\n","        train_imgs = images[:train_split]\n","        val_imgs = images[train_split:train_split + val_split]\n","        test_imgs = images[train_split + val_split:]\n","\n","        splits_dict = {\"train\": train_imgs, \"val\": val_imgs, \"test\": test_imgs}\n","\n","\n","        for split, img_list in splits_dict.items():\n","            for img_name in tqdm(img_list, desc=f\"{category} → {split}\"):\n","                img_path = os.path.join(img_folder, img_name)\n","                img = cv2.imread(img_path)\n","\n","                if img is None:\n","                    continue  # skip broken or unreadable images\n","\n","                processed_img = preprocess_image(img)\n","                save_path = os.path.join(output_dir, split, category, img_name)\n","                cv2.imwrite(save_path, processed_img)\n","\n","split_dataset()\n","print(\"Dataset split and preprocessing complete!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0RD3BzwYvYq","executionInfo":{"status":"ok","timestamp":1763025195865,"user_tz":-360,"elapsed":1523398,"user":{"displayName":"Tanzina Aranya Islam","userId":"18148284528936325680"}},"outputId":"7df1453f-12e7-4f2e-e7c1-259a893079f4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["COVID → train: 100%|██████████| 2892/2892 [02:37<00:00, 18.38it/s]\n","COVID → val: 100%|██████████| 361/361 [00:12<00:00, 28.69it/s]\n","COVID → test: 100%|██████████| 363/363 [00:12<00:00, 28.86it/s]\n","Lung_Opacity → train: 100%|██████████| 4809/4809 [06:15<00:00, 12.79it/s]\n","Lung_Opacity → val: 100%|██████████| 601/601 [00:21<00:00, 27.70it/s]\n","Lung_Opacity → test: 100%|██████████| 602/602 [00:21<00:00, 28.30it/s]\n","Normal → train: 100%|██████████| 8153/8153 [12:56<00:00, 10.50it/s]\n","Normal → val: 100%|██████████| 1019/1019 [00:36<00:00, 27.91it/s]\n","Normal → test: 100%|██████████| 1020/1020 [00:37<00:00, 27.46it/s]\n","Viral Pneumonia → train: 100%|██████████| 1076/1076 [01:00<00:00, 17.91it/s]\n","Viral Pneumonia → val: 100%|██████████| 134/134 [00:05<00:00, 24.47it/s]\n","Viral Pneumonia → test: 100%|██████████| 135/135 [00:04<00:00, 27.04it/s]"]},{"output_type":"stream","name":"stdout","text":["Dataset split and preprocessing complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["\n","def count_images(output_dir, splits, categories):\n","    print(\"\\nImage count per split and class:\")\n","    for split in splits:\n","        print(f\"\\n{split.upper()}: \")\n","        for category in categories:\n","            folder_path = os.path.join(output_dir, split, category)\n","            if os.path.exists(folder_path):\n","                num_images = len([f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","                print(f\"{category}: {num_images} images\")\n","            else:\n","                print(f\"{category}: Folder not found\")\n","\n","# Call the counting function after preprocessing\n","count_images(output_dir, splits, categories)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H38_qadOfxNH","executionInfo":{"status":"ok","timestamp":1763025352253,"user_tz":-360,"elapsed":1913,"user":{"displayName":"Tanzina Aranya Islam","userId":"18148284528936325680"}},"outputId":"03985c40-102c-4242-f183-42582297c585"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Image count per split and class:\n","\n","TRAIN: \n","COVID: 2892 images\n","Lung_Opacity: 4809 images\n","Normal: 8153 images\n","Viral Pneumonia: 1076 images\n","\n","VAL: \n","COVID: 361 images\n","Lung_Opacity: 601 images\n","Normal: 1019 images\n","Viral Pneumonia: 134 images\n","\n","TEST: \n","COVID: 363 images\n","Lung_Opacity: 602 images\n","Normal: 1020 images\n","Viral Pneumonia: 135 images\n"]}]},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","from tqdm import tqdm\n","\n","source_dir = \"/content/drive/MyDrive/Dataset Covid19/Covid-19_processed\"  # your preprocessed dataset\n","output_dir = \"/content/drive/MyDrive/Dataset Covid19/Covid-19_small\"      # new smaller dataset\n","\n","categories = [\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\n","splits = [\"train\", \"val\", \"test\"]\n","\n","# ==== PARAMETERS ====\n","images_per_class = 500  # total images per class (across all splits)\n","train_ratio = 0.8\n","val_ratio = 0.1\n","test_ratio = 0.1\n","\n","# ==== CREATE OUTPUT FOLDERS ====\n","for split in splits:\n","    for category in categories:\n","        os.makedirs(os.path.join(output_dir, split, category), exist_ok=True)\n","\n","# ==== COPY RANDOMLY SELECTED IMAGES ====\n","for category in categories:\n","    # Collect all images from train, val, and test splits\n","    all_images = []\n","    for split in splits:\n","        src_folder = os.path.join(source_dir, split, category)\n","        imgs = [os.path.join(split, category, f)\n","                for f in os.listdir(src_folder)\n","                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n","        all_images.extend(imgs)\n","\n","    if len(all_images) < images_per_class:\n","        print(f\"⚠️ Warning: {category} has only {len(all_images)} available (less than 500). Using all.\")\n","        selected = all_images\n","    else:\n","        selected = random.sample(all_images, images_per_class)\n","\n","    # Split into 80:10:10\n","    total = len(selected)\n","    train_end = int(total * train_ratio)\n","    val_end = train_end + int(total * val_ratio)\n","\n","    train_imgs = selected[:train_end]\n","    val_imgs = selected[train_end:val_end]\n","    test_imgs = selected[val_end:]\n","\n","    split_map = {\n","        \"train\": train_imgs,\n","        \"val\": val_imgs,\n","        \"test\": test_imgs\n","    }\n","\n","    # Copy images to new subset\n","    for split, img_list in split_map.items():\n","        for rel_path in tqdm(img_list, desc=f\"{category} → {split}\", ncols=80):\n","            src_path = os.path.join(source_dir, rel_path)\n","            dest_path = os.path.join(output_dir, rel_path)\n","            os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n","            shutil.copy2(src_path, dest_path)\n","\n","print(\"\\n✅ Subset dataset creation complete!\")\n","print(f\"Saved at: {output_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXfQTtt7yzpd","executionInfo":{"status":"ok","timestamp":1763030461152,"user_tz":-360,"elapsed":108823,"user":{"displayName":"Tanzina Aranya Islam","userId":"18148284528936325680"}},"outputId":"1dfc57c1-67ed-43da-965c-54c2f9277d85"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["COVID → train: 100%|██████████████████████████| 400/400 [00:09<00:00, 41.44it/s]\n","COVID → val: 100%|██████████████████████████████| 50/50 [00:01<00:00, 41.12it/s]\n","COVID → test: 100%|█████████████████████████████| 50/50 [00:01<00:00, 49.74it/s]\n","Lung_Opacity → train: 100%|███████████████████| 400/400 [00:59<00:00,  6.73it/s]\n","Lung_Opacity → val: 100%|███████████████████████| 50/50 [00:00<00:00, 55.42it/s]\n","Lung_Opacity → test: 100%|██████████████████████| 50/50 [00:00<00:00, 57.24it/s]\n","Normal → train: 100%|█████████████████████████| 400/400 [00:14<00:00, 27.25it/s]\n","Normal → val: 100%|█████████████████████████████| 50/50 [00:00<00:00, 50.60it/s]\n","Normal → test: 100%|████████████████████████████| 50/50 [00:00<00:00, 52.52it/s]\n","Viral Pneumonia → train: 100%|████████████████| 400/400 [00:15<00:00, 25.46it/s]\n","Viral Pneumonia → val: 100%|████████████████████| 50/50 [00:01<00:00, 49.63it/s]\n","Viral Pneumonia → test: 100%|███████████████████| 50/50 [00:00<00:00, 54.42it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","✅ Subset dataset creation complete!\n","Saved at: /content/drive/MyDrive/Dataset Covid19/Covid-19_small\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}